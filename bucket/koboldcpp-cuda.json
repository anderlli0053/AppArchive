{
    "version": "1.24",
    "description": "A simple one-file way to run various GGML models like LLAMA, ALPACA, VICUNA",
    "homepage": "https://github.com/LostRuins/koboldcpp",
    "license": "AGPL-3.0",
    "notes": "Look Mobel *.bin weights at https://rentry.org/nur779",
    "architecture": {
        "64bit": {
            "url": "https://github.com/LostRuins/koboldcpp/releases/download/v1.24/koboldcpp_CUDA_only.exe",
            "hash": "97DAE329FF496B044172AAA708BBAE2C98F3857D982F46E097E801A9BEFC7C87"
        }
    },
    "bin": "koboldcpp_CUDA_only.exe",
    "shortcuts": [
        [
            "koboldcpp_CUDA_only.exe",
            "KoboldCpp"
        ]
    ]
}
